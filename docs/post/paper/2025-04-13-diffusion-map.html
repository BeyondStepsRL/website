<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jungyeon Lee">
<meta name="dcterms.date" content="2025-04-13">
<meta name="description" content="Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation">

<title>Diffusion 아이디어 – BSRL</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-698eeccc465cafbf8f1934b30c85bcac.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">BSRL</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../post.html"> 
<span class="menu-text">Post</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../competition.html"> 
<span class="menu-text">Competition</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../goal.html"> 
<span class="menu-text">Goal</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#강화학습을-위한-적응형-디퓨전-지형-생성기" id="toc-강화학습을-위한-적응형-디퓨전-지형-생성기" class="nav-link active" data-scroll-target="#강화학습을-위한-적응형-디퓨전-지형-생성기">강화학습을 위한 적응형 디퓨전 지형 생성기</a>
  <ul class="collapse">
  <li><a href="#diffusion-model-간단-소개" id="toc-diffusion-model-간단-소개" class="nav-link" data-scroll-target="#diffusion-model-간단-소개">Diffusion Model 간단 소개</a></li>
  </ul></li>
  <li><a href="#문제-정의" id="toc-문제-정의" class="nav-link" data-scroll-target="#문제-정의">문제 정의</a></li>
  <li><a href="#방법" id="toc-방법" class="nav-link" data-scroll-target="#방법">방법</a>
  <ul class="collapse">
  <li><a href="#지형-인식-정책-최적화를-위한-적응형-커리큘럼-학습" id="toc-지형-인식-정책-최적화를-위한-적응형-커리큘럼-학습" class="nav-link" data-scroll-target="#지형-인식-정책-최적화를-위한-적응형-커리큘럼-학습">지형 인식 정책 최적화를 위한 적응형 커리큘럼 학습</a></li>
  <li><a href="#디퓨전으로-지형을-생성하는-방법" id="toc-디퓨전으로-지형을-생성하는-방법" class="nav-link" data-scroll-target="#디퓨전으로-지형을-생성하는-방법">디퓨전으로 지형을 생성하는 방법</a>
  <ul class="collapse">
  <li><a href="#초기-노이즈-최적화와-latent-보간" id="toc-초기-노이즈-최적화와-latent-보간" class="nav-link" data-scroll-target="#초기-노이즈-최적화와-latent-보간">1. 초기 노이즈 최적화와 latent 보간</a></li>
  <li><a href="#diffusion-노이즈-단계-조절로-다양성-확보" id="toc-diffusion-노이즈-단계-조절로-다양성-확보" class="nav-link" data-scroll-target="#diffusion-노이즈-단계-조절로-다양성-확보">2. diffusion 노이즈 단계 조절로 다양성 확보</a></li>
  <li><a href="#control-as-inference로-본-노이즈-보간" id="toc-control-as-inference로-본-노이즈-보간" class="nav-link" data-scroll-target="#control-as-inference로-본-노이즈-보간">3. Control-as-Inference로 본 노이즈 보간</a></li>
  </ul></li>
  <li><a href="#커리큘럼-강화학습과-adtg의-연계" id="toc-커리큘럼-강화학습과-adtg의-연계" class="nav-link" data-scroll-target="#커리큘럼-강화학습과-adtg의-연계">커리큘럼 강화학습과 ADTG의 연계</a></li>
  </ul></li>
  <li><a href="#지형-데이터" id="toc-지형-데이터" class="nav-link" data-scroll-target="#지형-데이터">지형 데이터</a>
  <ul class="collapse">
  <li><a href="#네트워크-구조" id="toc-네트워크-구조" class="nav-link" data-scroll-target="#네트워크-구조">네트워크 구조</a></li>
  </ul></li>
  <li><a href="#결과" id="toc-결과" class="nav-link" data-scroll-target="#결과">결과</a>
  <ul class="collapse">
  <li><a href="#실험-셋팅" id="toc-실험-셋팅" class="nav-link" data-scroll-target="#실험-셋팅">실험 셋팅</a></li>
  <li><a href="#실험-결과" id="toc-실험-결과" class="nav-link" data-scroll-target="#실험-결과">실험 결과</a></li>
  <li><a href="#족-보행-로봇-실험" id="toc-족-보행-로봇-실험" class="nav-link" data-scroll-target="#족-보행-로봇-실험">4족 보행 로봇 실험</a></li>
  <li><a href="#디퓨전-기반-지형-생성의-장점과-향후-전망" id="toc-디퓨전-기반-지형-생성의-장점과-향후-전망" class="nav-link" data-scroll-target="#디퓨전-기반-지형-생성의-장점과-향후-전망">디퓨전 기반 지형 생성의 장점과 향후 전망</a></li>
  </ul></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference">Reference</a></li>
  <li><a href="#todo" id="toc-todo" class="nav-link" data-scroll-target="#todo">TODO</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Diffusion 아이디어</h1>
  <div class="quarto-categories">
    <div class="quarto-category">diffusion</div>
  </div>
  </div>

<div>
  <div class="description">
    Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jungyeon Lee </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 13, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<ul>
<li>논문 <a href="https://openreview.net/forum?id=xYleTh2QhS">원문</a></li>
<li>코드 <a href="https://github.com/youwyu/Adaptive-Diffusion-Terrain">Repository</a> : ROS 코드는 공개 안함</li>
<li><a href="https://adtg-sim-to-real.github.io">프로젝트 페이지</a></li>
</ul>
<section id="강화학습을-위한-적응형-디퓨전-지형-생성기" class="level1">
<h1>강화학습을 위한 적응형 디퓨전 지형 생성기</h1>
<blockquote class="blockquote">
<p>Adaptive Diffusion Terrain Generator (ADTG)</p>
</blockquote>
<p>로봇이 울퉁불퉁한 지형을 안정적으로 주행하려면, 학습 단계에서 다양한 어려운 지형을 경험해야 합니다. 최근 강화학습(RL)을 활용한 로봇 제어가 발전하면서 시뮬레이션을 통한 <strong>환경 생성</strong>이 중요한 역할을 하고 있습니다. 그러나 기존의 환경 생성 방법들은 보통 수동 설계한 몇 가지 매개변수에 의존하기 때문에 지형의 <strong>다양성</strong>이나 <strong>현실감</strong>이 제한되는 문제가 있습니다. 이러한 한계 때문에 학습된 정책이 새로운 실제 환경에 일반화하기 어려운 경우가 많았습니다.</p>
<p>이 글에서는 CoRL 2024에 발표된 <strong>Adaptive Diffusion Terrain Generator (ADTG)</strong> 방법을 소개합니다. ADTG는 <strong>디퓨전 모델</strong>(DDPM, Denoising Diffusion Probabilistic Model)을 활용해 현재 정책의 성능에 맞춰 지형의 난이도와 다양성을 <strong>적응적으로</strong> 조절하며 새로운 지형을 생성하는 기법입니다. 요컨대, 학습이 진행됨에 따라 정책이 너무 익숙해지거나 쉽게 느끼는 환경은 더 복잡하게 만들고, 반대로 너무 어려운 환경은 피하면서 <strong>맞춤형 커리큘럼</strong>을 자동으로 구성해주는 환경 생성기라 볼 수 있습니다.</p>
<hr>
<section id="diffusion-model-간단-소개" class="level2">
<h2 class="anchored" data-anchor-id="diffusion-model-간단-소개">Diffusion Model 간단 소개</h2>
<p><strong>DDPM(Denoising Diffusion Probabilistic Model)</strong>은 최근 이미지 생성 등 분야에서 각광받는 <strong>생성 모델</strong>의 한 종류입니다. 기본 아이디어는 매우 <strong>간단</strong>합니다:</p>
<p>모델은 먼저 이미지나 신호에 <strong>점차적으로 노이즈를 추가</strong>해 데이터를 <strong>파괴</strong>(destroy)하는 과정을 정의하고, 역으로 그렇게 <strong>섞인 노이즈를 단계적으로 제거</strong>하며 <strong>새로운 샘플을 생성</strong>하는 과정을 학습합니다. 다시 말해, <strong>앞방향 과정</strong>에서는 깨끗한 데이터에 조금씩 가우시안 노이즈를 덧붙여 최종적으로 거의 무작위 노이즈 상태까지 만드는 반면, <strong>역방향 과정</strong>에서는 완전한 노이즈에서 시작해 한 단계씩 노이즈를 제거(denoise)하면서 데이터를 복원하듯이 <strong>샘플을 만들어내는</strong> 것입니다. 모델은 이러한 <strong>노이즈 추가/제거 과정</strong> 전체를 확률적으로 학습하여, 최종적으로 <strong>아무것도 없는 상태(백색 노이즈)</strong>에서 출발해도 훈련 데이터와 유사한 새로운 데이터를 생성할 수 있게 됩니다.</p>
<center>
<img src="../../images/2025-04-13-diffusion-map/2.png" width="60%">
<figcaption>
Diffusion Mechanism
</figcaption>
</center>
<p>DDPM은 새로운 데이터를 만들어낼 때 <strong>다양하고 섬세한 제어</strong>가 가능하다는 것입니다. 예를 들어 조건부 샘플링이나 guidance 기법을 통해 원하는 스타일이나 특성을 유도할 수 있습니다. ADTG에서는 이러한 디퓨전 모델의 표현력과 제어 가능성을 <strong>지형 생성 문제에 적용</strong>합니다.</p>
</section>
</section>
<section id="문제-정의" class="level1">
<h1>문제 정의</h1>
<p>지형을 그리드 기반의 heightmap을 사용하여 표현하며, 그것을 <span class="math inline">\(e ∈ R^{W × H}\)</span>로 나타냅니다. 여기서 <span class="math inline">\(W\)</span>와 <span class="math inline">\(H\)</span>는 각각 너비와 높이를 나타냅니다. <span class="math display">\[
\theta^* = \arg \max_{\theta} \mathbb{E}_{a_t \sim \pi(a_t | s_t, e), s_0 \sim p(s_0), e \sim p(e), s_{t+1} \sim p(s_{t+1} | s_t, a_t, e)} \left[ \sum_{t=0}^{T} \gamma^t R(s_t, a_t) \right],
\]</span></p>
<p>고도 <span class="math inline">\(e\)</span>가 로봇의 이동에 제약을 부과하기 때문에, 위의 식을 통해 최적화된 정책은 본질적으로 <strong>높은 지형에서의 위험을 피할 수 있는 능력을 갖추고 있습니다.</strong> 정책의 성능에 따라 환경 분포 <span class="math inline">\(p(e)\)</span>를 동적으로 진화시키는 것을 목표로 하여 훈련 효율성을 보장하고 현실적인 지형 고도를 생성합니다.</p>
</section>
<section id="방법" class="level1">
<h1>방법</h1>
<section id="지형-인식-정책-최적화를-위한-적응형-커리큘럼-학습" class="level2">
<h2 class="anchored" data-anchor-id="지형-인식-정책-최적화를-위한-적응형-커리큘럼-학습">지형 인식 정책 최적화를 위한 적응형 커리큘럼 학습</h2>
<p>사실상 현실적으로 모든 heightmap에 대해서 학습할 수는 없습니다. 비현실적인 해법은 모든 가능한 지형 <span class="math inline">\(\Lambda = (e_1, ..., e_N)\)</span>에서 훈련하는 것입니다. 이때 <span class="math inline">\(p(e)\)</span>는 <span class="math inline">\(\Lambda\)</span>에 대한 균일 분포로 설정됩니다.</p>
<p>효과적인 환경 생성기를 설계하는 것이 중요합니다.</p>
<ol type="1">
<li><p>현실 세계의 분포와 일치하는 현실적인 환경을 생성하고</p></li>
<li><p>현재 정책에 적절한 도전을 제공해야 합니다.</p></li>
</ol>
<p>조정 가능한 미리 정의된 지형 유형은 제어가 가능하다는 장점이 있지만 다양성이 부족할 수 있으며, 생성 모델은 현실성 면에서는 뛰어나지만 정책에 정확히 맞춘 도전 과제 설정에는 한계가 있을 수 있습니다.</p>
</section>
<section id="디퓨전으로-지형을-생성하는-방법" class="level2">
<h2 class="anchored" data-anchor-id="디퓨전으로-지형을-생성하는-방법">디퓨전으로 지형을 생성하는 방법</h2>
<blockquote class="blockquote">
<p>4장 Adaptive Diffusion Terrain Generator</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/2025-04-13-diffusion-map/3.png" class="img-fluid figure-img"></p>
<figcaption>3</figcaption>
</figure>
</div>
<ul>
<li>DDPM 잠재 공간에서 “쉬운” 지형과 “어려운” 지형 간의 보간을 통해 정책 훈련을 최적화하는 지형을 생성</li>
<li>훈련 데이터셋의 분산에 따라 초기 노이즈 입력을 조정하여 지형의 다양성을 풍부하게 하여 더 넓은 경험을 조성하고 보이지 않는 지형에서 정책의 일반화를 개선</li>
</ul>
<p>ADTG의 핵심 아이디어는 <strong>이미 학습된</strong> 디퓨전 모델을 활용해 현재 정책에 가장 도움이 될 <strong>새로운 지형을 생성</strong>하되, 그 생성 과정을 <strong>현재 정책의 성능 지표</strong>로 <strong>안내(guidance)</strong>한다는 것입니다. 이를 위해 ADTG는 <strong>두 가지 주요 단계로 진행</strong>:</p>
<p><strong>(1)</strong> 정책 성능 기반 지형 생성 (Performance-Guided Generation): DDPM의 latent variable (noise)을 합성하여 정책 훈련을 최적화하는 지형을 생성합니다.</p>
<p><strong>(2)</strong> 초기 노이즈 조정을 통한 훈련 데이터셋 다양화 (Diversifying Training Dataset): 훈련 데이터셋의 variance에 따라 초기 노이즈 수준을 조절하여 지형 다양성을 증가시키고 정책의 일반화 능력을 향상시킵니다.</p>
<hr>
<section id="초기-노이즈-최적화와-latent-보간" class="level3">
<h3 class="anchored" data-anchor-id="초기-노이즈-최적화와-latent-보간">1. 초기 노이즈 최적화와 latent 보간</h3>
<p>일반적으로 디퓨전 모델로 새로운 샘플을 생성하려면 우선 <strong>초기 노이즈(<span class="math inline">\(e_K\)</span>)</strong>를 무작위로 뽑아서 역확산(reverse diffusion)을 진행합니다. <strong>하지만 ADTG에서는 이 초기 노이즈를 무작위로 선택하지 않고 최적화합니다.</strong></p>
<ul>
<li><span class="math inline">\(e\)</span>, <span class="math inline">\(e_0\)</span>, <span class="math inline">\(e_k\)</span>를 훈련 데이터셋의 환경, DDPM을 통해 생성된 지형, 그리고 시간 단계 k의 DDPM 잠재 변수로 각각 나타냅니다. 이 세 변수는 모두 동일한 크기 <span class="math inline">\(R^{W × H}\)</span></li>
</ul>
<p>구체적으로, 현재 <strong>훈련 데이터셋</strong>에 포함된 지형들 중에서 일부를 선택하고, 각 지형 <span class="math inline">\(e_i\)</span>에 대해 디퓨전 <strong>앞방향</strong>을 <span class="math inline">\(k\)</span> 단계 진행하여 <strong>latent 표현</strong> <span class="math inline">\(e_i^k\)</span>를 얻습니다. 여기서 <span class="math inline">\(k\)</span>는 일종의 <strong>중간 노이즈 수준</strong>을 나타내는 하이퍼파라미터로, <span class="math inline">\(k=0\)</span>이면 원본 지형(노이즈 없음), <span class="math inline">\(k=K\)</span>이면 완전한 가우시안 노이즈에 해당합니다. 이렇게 얻은 여러 개의 부분 노이즈 지형(latent)들을 <strong>합성(combine)</strong>하여 새로운 초기 노이즈 <span class="math inline">\(e'_k\)</span>를 만들고자 하는데, 단순 평균이 아니라 <strong>정책의 성능에 기반한 가중 합으로 결합하는 것</strong>이 포인트입니다.</p>
<p><span class="math display">\[e'_k = \frac{\sum_i w(e_i, \pi)\; e_i^k}{\sum_i w(e_i, \pi)}\]</span></p>
<p>위 식에서 <span class="math inline">\(w(e_i, \pi)\)</span>는 <strong>지형 <span class="math inline">\(e_i\)</span>에 대한 현재 정책 <span class="math inline">\(\pi\)</span>의 성능</strong>에 따라 달라지는 가중치입니다. 예를 들어, 어떤 지형에서 정책이 너무 쉽게 100% 성공한다면 그 지형은 학습에 덜 유용할 수 있고(너무 쉬움), 반대로 성공률이 0%에 가깝다면 현재 정책 수준에서는 너무 어려운 환경일 것입니다. ADTG는 가장 <strong>학습 효과</strong>가 좋은 <strong>중간 난이도</strong>를 목표로 가중치를 부여합니다.</p>
<p>논문에서는 정책의 <strong>성공률</strong>을 난이도 척도 <span class="math inline">\(s(e,\pi)\)</span>로 사용하고, 목표 성공률을 <span class="math inline">\(\bar{s}\)</span>로 정한 뒤 각 지형의 가중치를 <span class="math display">\[w(e,\pi) = \exp\!\Big(-\frac{(s(e,\pi)-\bar{s})^2}{\sigma^2}\Big)\]</span> 와 같이 설정합니다. 즉, <strong>성공률 <span class="math inline">\(s\)</span>가 목표 <span class="math inline">\(\bar{s}\)</span>와 가까운 지형일수록 가중치가 높아지고</strong>, 너무 쉽거나 너무 어려워서 성공률이 극단적인 지형은 가중치가 낮아지도록 <strong>가우시안 형태</strong>로 penalize한 것입니다. 이렇게 하면 현재 정책에게 <strong>적절한 난이도</strong>의 지형들이 초기 노이즈 합성에 더 큰 기여를 하게 됩니다.</p>
<center>
<p>결과적으로, <span class="math inline">\(e'_k\)</span>는 여러 기존 지형들의 특징을 <strong>성능 기반 가중치</strong>로 <strong>블렌딩</strong>한 <strong>중간 노이즈 상태</strong></p>
</center>
<p>이 <span class="math inline">\(e'_k\)</span>를 디퓨전 모델의 역방향 과정에 투입하여 <span class="math inline">\(k\)</span>부터 <span class="math inline">\(0\)</span>까지 거꾸로 진행하면 최종적으로 <strong>새로운 지형 <span class="math inline">\(e'_0\)</span>가 생성</strong>됩니다. 이 지형은 기여한 지형들로부터 전반적인 기복 패턴과 같은 고수준의 특징을 물려받되, 세부적으로는 디퓨전 모델의 확률적 생성 특성 덕분에 완전히 동일하지는 않은 변형된 지형이 됩니다. 쉽게 말하면, <strong>여러 환경의 DNA를 섞어서 새로운 난이도의 환경을 만들어내는 것</strong>과 비슷합니다. 가중치 <span class="math inline">\(w_i\)</span>를 어떻게 주느냐에 따라 난이도를 조절할 수 있는데요, 하나의 환경에 무게를 많이 두면 그 환경과 비슷한 지형이 나오고, 여러 환경을 고르게 섞으면 좀 더 새로운 느낌의 지형이 만들어집니다.</p>
</section>
<section id="diffusion-노이즈-단계-조절로-다양성-확보" class="level3">
<h3 class="anchored" data-anchor-id="diffusion-노이즈-단계-조절로-다양성-확보">2. diffusion 노이즈 단계 조절로 다양성 확보</h3>
<p>위 과정만으로도 정책에 맞춘 난이도의 지형을 만들어낼 수 있지만, 학습이 진행됨에 따라 <strong>훈련 데이터셋의 다양성이 점점 부족해지는 문제</strong>가 발생할 수 있습니다. 정책이 성장하면서 기존 지형들을 모두 정복하게 되면, 아무리 그들을 섞는다 해도 더 이상 새로운 자극을 주기가 어렵기 때문입니다. 이때 필요한 것이 지형의 <strong>완전히 새로운 형태</strong>, 즉 <strong>다양성(diversity)</strong>입니다.</p>
<p>ADTG는 이를 위해 <strong>디퓨전 과정의 시작 단계 <span class="math inline">\(k\)</span></strong>를 동적으로 조절하여 출력 지형의 <strong>참신함(novelty)</strong>을 제어합니다.</p>
<ul>
<li>디퓨전의 노이즈 단계 <strong><span class="math inline">\(k\)</span>를 크게 하면</strong> 할수록 최종 생성되는 지형이 <strong>본래 지형들과 동떨어진 새로운 모습</strong>을 띠게 되고,</li>
<li>반대로 <strong><span class="math inline">\(k\)</span>를 작게</strong> (즉 기존 지형에 적은 노이즈만 추가) 하면 생성물이 <strong>원래 환경들과 유사한 모습</strong>을 유지한다는 점입니다.</li>
<li><strong>무작위 노이즈에서 시작</strong>하면 디퓨전 모델이 다양한 결과를 만들 수 있지만, <strong>원본에 가까운 상태에서 시작</strong>하면 변화의 폭이 적기 때문입니다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/2025-04-13-diffusion-map/4.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1-(a)</figcaption>
</figure>
</div>
<p>실제로 논문 Figure 1-(a)에서도 <strong>forward step <span class="math inline">\(K\)</span></strong>(노이즈 단계)가 증가할수록 생성 지형의 <strong>분산</strong>(다양성)이 커지는 모습을 확인할 수 있습니다 TG는 현재 <strong>훈련 데이터셋의 다양성 지표</strong>를 측정하여, 다양성이 낮다고 판단되면 더 높은 <span class="math inline">\(k\)</span>를 사용하고, 다양성이 충분하면 낮은 <span class="math inline">\(k\)</span>를 사용하도록 합니다. 구체적으로, 지형 데이터셋의 표본들에 대해 <strong>주성분 분석(PCA)</strong>으로 몇 가지 주요 성분의 <strong>분산 <span class="math inline">\(\Lambda_{\text{var}}\)</span></strong>을 계산하고, 이를 0~1로 정규화하여 <strong>현재 데이터셋 다양성 척도</strong>로 삼습니다.</p>
<center>
<p><span class="math inline">\(k = K (1 - \Lambda_{\text{var}})\)</span>로 설정하는 <strong>선형 스케줄러</strong>를 사용</p>
</center>
<p>여기서 <span class="math inline">\(K\)</span>는 디퓨전 모델의 최대 시간 단계(예: 모델이 학습된 총 노이즈 단계)입니다. 이 식의 의미는</p>
<ul>
<li><p><strong>데이터셋 다양성 <span class="math inline">\(\Lambda_{\text{var}}\)</span>가 낮을수록 <span class="math inline">\(k\)</span>를 크게 잡아</strong> (즉 더 앞쪽 노이즈 단계에서 시작하여) <strong>새롭고 다양한 지형</strong>을 만들고,</p></li>
<li><p><strong>다양성이 높을수록 <span class="math inline">\(k\)</span>를 작게</strong> 하여 <strong>기존과 비슷하지만 난이도 있는 지형</strong>을 만드는 쪽으로 조절한다는 것입니다.</p></li>
</ul>
<p>이렇게 함으로써 학습이 진행되는 동안 <strong>지형 다양성의 정체</strong>로 인한 정책 성능 정체를 방지하고, 계속해서 훈련 환경 풀(pool)을 확장시킬 수 있습니다.</p>
<blockquote class="blockquote">
<p>요약하면, ADTG는 <strong>난이도</strong>는 정책에 맞게 유지하되, 필요에 따라 <strong>노이즈를 더 섞어서</strong> 완전히 새로운 지형을 투입함으로써 <strong>커리큘럼의 폭을 넓히는 역할</strong>을 합니다.</p>
</blockquote>
</section>
<section id="control-as-inference로-본-노이즈-보간" class="level3">
<h3 class="anchored" data-anchor-id="control-as-inference로-본-노이즈-보간">3. Control-as-Inference로 본 노이즈 보간</h3>
<p>흥미롭게도, ADTG의 이러한 <strong>노이즈 최적화 및 보간 전략</strong>은 <strong>제어를 추론 문제로 보는 관점(Control-as-Inference)</strong>으로 해석할 수도 있습니다. 원래 강화학습에서의 <strong>최적 제어</strong> 문제를 확률적 추론으로 나타낼 수 있다는 아이디어인데, 여기서는 반대로 <strong>환경을 생성하는 문제</strong>를 <strong>정책 향상이라는 목표 하에</strong> 하나의 추론과정으로 본 것입니다.</p>
<p>논문 부록(A)에 따르면, 앞서 “문제 정의”에서 소개한 식의 최적화는 KL 제어 이론을 통해 유도될 수 있다고 합니다. 새로운 지형을 생성하는 것은 곧 <strong>어떤 초기 노이즈 <span class="math inline">\(e_k\)</span>를 선택</strong>하는 문제이며, 그 노이즈를 시작으로 디퓨전 모델을 통해 만들어진 최종 지형 <span class="math inline">\(e_0\)</span>에서 <strong>정책의 성능 향상</strong>이 최대화되길 바랍니다. 이 목표를 직접 달성하려면 <span class="math inline">\(e_k\)</span>에 대한 <strong>목표 함수(J)</strong>를 최대화하는 최적화를 해야겠지만, 정책 성능 향상은 <strong>시뮬레이션을 돌려봐야 알 수 있기 때문에</strong> 미분 가능하지 않고 비싼 계산입니다.</p>
<p>대신 이를 <strong>확률적 샘플링 문제</strong>로 변환하여, 성능이 좋은 환경이 나올 <strong>확률을 높이는 방식</strong>으로 접근합니다. 간단히 말해, <strong>“좋은 지형일수록 더 자주 뽑히도록 하자”</strong>는 것입니다.</p>
<p>수식적으로는 <strong>참조 분포</strong> <span class="math inline">\(q(e_k)\)</span> (예: 기존 데이터셋 지형들을 일정 수준 노이즈 넣은 분포)로부터 샘플링된 후보들 중 <strong>return(정책 향상)이 높은 쪽에 가중치를 실어주는</strong> 형태로 해석할 수 있고, 그 결과 <strong>중요도 샘플링(importance sampling)</strong>을 통해 최적 노이즈의 기대값을 구하면 바로 앞서 사용한 <strong>가중치 평균 식으로 수렴</strong>합니다. 제어-추론 관점에서 보면, <strong>높은 보상을 줄 환경을 샘플링하는 확률분포의 기대값</strong>을 계산한 것과 같으며, 이것이 이론적으로 <strong>정당화</strong>된다는 것이죠.</p>
<p>정리하면, ADTG의 기법은 처음부터 끝까지 <strong>정책의 성능 신장</strong>이라는 목적을 갖고 설계되었고, 이를 확률적 생성 모델(Diffusion)의 제어 변수(초기 노이즈)를 <strong>학습자(정책)</strong>의 상태에 맞춰 조절함으로써 구현한 것이라 볼 수 있습니다. 이제 이러한 ADTG가 <strong>강화학습 커리큘럼</strong>과 어떻게 맞물려 돌아가는지 알아보겠습니다.</p>
</section>
</section>
<section id="커리큘럼-강화학습과-adtg의-연계" class="level2">
<h2 class="anchored" data-anchor-id="커리큘럼-강화학습과-adtg의-연계">커리큘럼 강화학습과 ADTG의 연계</h2>
<p>ADTG는 본질적으로 <strong>자동 커리큘럼</strong>을 구성하기 위한 <strong>환경 생성기</strong>로 설계되었습니다. 알고리즘의 작동 형태는 다음과 같습니다: 우선 초기에는 일부 기본 환경(elevation map)을 가지고 정책을 훈련하다가, 일정 주기마다 (혹은 병렬 학습 과정에서 지속적으로) 현재 정책에 맞는 새 지형을 <strong>생성하여 데이터셋에 추가</strong>합니다. 특히 매 반복(iteration)마다 <strong>현재 정책에게 가장 효과적인 학습 신호</strong>를 줄 환경을 <strong>선택</strong>하여 그 환경에서 정책을 조금 더 학습시킨 후, ADTG를 통해 새로운 환경을 만들어내는 식으로 진행됩니다. 이때 환경 선택은 앞서 정의한 가중치 함수 <span class="math inline">\(w(e,\pi)\)</span>를 활용해 <strong>현재 가장 적절한 난이도의 지형</strong>을 뽑습니다. 반드시 최고 가중치 하나만 고르는 대신, <strong>확률적으로 샘플링</strong>하여 <strong>편중되지 않게</strong> 다양한 환경을 경험하도록 할 수도 있습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/2025-04-13-diffusion-map/7.png" class="img-fluid figure-img"></p>
<figcaption>7</figcaption>
</figure>
</div>
<center>
<p>이러한 절차를 통해 <strong>정책과 환경</strong>이 함께 <strong>공진화(co-evolve)</strong>하게 됩니다.</p>
</center>
<p>정책이 발전하면 새로운 환경이 추가되고, 그 환경에서 다시 정책을 훈련하며, 시간이 지날수록 데이터셋은 점점 다양하고 어려운 지형들을 포함하게 됩니다. 이는 사람의 학습 과정에서 난이도를 조금씩 높여가며 실력을 향상시키는 <strong>교육 커리큘럼</strong>과 유사합니다. ADTG는 수동으로 커리큘럼을 설계하지 않아도 <strong>정책의 성공률 등 성능 측정치에 따라 난이도를 자동 조절</strong>해주므로, 일종의 <strong>자율 교사</strong> 역할을 수행한다고 볼 수 있습니다. 특히 강화학습에서 중요한 exploration-exploitation balance를 유지하면서도, 너무 쉬운 환경에 안주하거나 너무 어려운 환경에서 학습이 실패하는 상황을 방지하는 장점이 있습니다.</p>
</section>
</section>
<section id="지형-데이터" class="level1">
<h1>지형 데이터</h1>
<blockquote class="blockquote">
<p>부록 C</p>
</blockquote>
<p>규칙한 지형 데이터셋. 데이터셋 생성을 위해 실제 고해상도 지형 데이터셋에서 얻은 래스터로 표현된 디지털 고도 모델(DEM)을 활용합니다. 전체 지도는 해상도가 0.1m인 [128 × 128] 크기의 타일로 나누어집니다. DDPM을 위한 3000개의 훈련 데이터와 알고리즘 성능 평가를 위한 100개의 평가 데이터가 특정 지리적 범위 내에서 무작위로 선택됩니다.</p>
<section id="네트워크-구조" class="level2">
<h2 class="anchored" data-anchor-id="네트워크-구조">네트워크 구조</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/2025-04-13-diffusion-map/5.png" class="img-fluid figure-img"></p>
<figcaption>5</figcaption>
</figure>
</div>
<p>특권(교사) 정책과 배포(학생) 정책 모두 인코더-디코더 아키텍처를 기반으로 합니다. 인코더는 지형의 고도 또는 깊이 이미지를 입력으로 받아 특징 표현을 추출하며, 이를 위해 ResNet-18의 초기 16개 계층을 활용합니다.</p>
<p>배포 정책은 선형 및 각도 명령 생성을 위해 신경 회로 정책(NCP), 그중에서도 폐쇄형 연속 시간(CfC) 네트워크를 사용합니다. Vanilla RNN, LSTM, GRU, NCP 모두 충분한 학습 단계를 거치면 유사한 정확도를 달성할 수 있지만, NCP는 훨씬 적은 수의 매개변수로도 우수한 성능을 보여 최종적으로 선택되었습니다.</p>
</section>
</section>
<section id="결과" class="level1">
<h1>결과</h1>
<section id="실험-셋팅" class="level2">
<h2 class="anchored" data-anchor-id="실험-셋팅">실험 셋팅</h2>
<p>Velodyne-16 LiDAR, RealSense D435i 카메라 및 3DM-GX5-25 IMU가 장착되어 있습니다. 풀, 숲, 건조, 녹, 진흙, 자갈, 사막 하드, 사막 터프 및 사막 전문가 등 9개의 다양한 대표 환경에서 테스트합니다.</p>
</section>
<section id="실험-결과" class="level2">
<h2 class="anchored" data-anchor-id="실험-결과">실험 결과</h2>
<p>ADTG의 저자들은 이 방법을 wheeled robot인 <strong>Jackal</strong> 및 <strong>Husky</strong> 로봇의 주행 정책 학습에 적용하여, <strong>시뮬레이션</strong>과 <strong>실제 야외 환경</strong> 실험을 모두 진행했습니다. 30개의 다양하고 거친 지형<strong>을 준비해 여러 최신 강화학습 및 플래너 기반 방법들과 비교한 결과, ADTG로 학습한 정책이 </strong>성공률, 주행 안정성 등 여러 지표에서 <strong>가장 우수한 성능</strong>을 보였습니다. 특히 ADTG는 학습 속도도 빨라서, 복잡한 지형에 대한 <strong>정책 수렴 속도</strong>가 기존 커리큘럼 방식들보다 향상되었음을 확인했습니다.</p>
<p>더 놀라운 것은 <strong>sim-to-real</strong> 실험 결과로, 시뮬레이션에서 한 번도 보지 못한 새로운 실제 환경들(예: <strong>숲</strong>, <strong>진흙</strong>, <strong>자갈</strong>, <strong>모래 언덕</strong> 등 총 9종의 지형)에서 <strong>무학습 전이(Zero-shot)</strong>로 평가를 진행했는데도, ADTG로 훈련된 정책이 대부분의 환경에서 <strong>안정적으로 로봇을 주행</strong>시켰습니다 rics)). 반면, 고정된 절차적 생성이나 한정된 자연 지형 데이터로만 학습한 정책은 일부 현실 환경에서 거의 움직이지 못하거나 전복되는 등 일반화 성능이 떨어지는 모습을 보였습니다. 이 실험을 통해 ADTG의 <strong>적응형 생성</strong>이 시뮬레이션과 현실 사이의 갭을 줄여주고, <strong>견고한 정책</strong>을 만들어내는 데 효과적임이 입증되었습니다.</p>
<center>
<img src="../../images/2025-03-22-diffusion-map/e5fbc468-c4ec-4fad-a9e3-986dfb01a099.png" width="30%">
<figcaption>
예시: 비교적 <strong>완만한 지형</strong> (정책에게 <strong>쉬운 환경</strong>에 해당)
</figcaption>
</center>
<center>
<img src="../../images/2025-03-22-diffusion-map/dcd43b2e-8c45-4b67-b223-264fc08729cd.png" width="30%">
<figcaption>
예시: 기복이 심한 <strong>거친 지형</strong> (정책에게 <strong>어려운 환경</strong>에 해당)
</figcaption>
</center>
<p>위 이미지는 ADTG 저자들이 제시한 예시로, 좌측은 <strong>쉬운 환경</strong>의 지형 예시이고 우측은 <strong>어려운 환경</strong> 지형입니다. ADTG는 이러한 쉬운/어려운 환경 정보를 반영하여 중간 정도 난이도의 새로운 지형을 만들어냅니다. 또한 노이즈 수준 <span class="math inline">\(k\)</span>를 조절함으로써, 필요할 경우 오른쪽 그림처럼 <strong>더 복잡하고 새로운 패턴</strong>의 지형도 생성해낼 수 있습니다. 이는 정책이 학습 초기에 단조로운 지형만 경험하는 것을 피하게 해주고, 후반에는 그동안 보지 못한 형태의 지형도 만나게 함으로써 <strong>예기치 않은 상황에 대한 대처 능력</strong>을 높여줍니다.</p>
</section>
<section id="족-보행-로봇-실험" class="level2">
<h2 class="anchored" data-anchor-id="족-보행-로봇-실험">4족 보행 로봇 실험</h2>
<p>실제 4족 보행 로봇 실험 환경에서는 지형의 크기가 [128 × 128], 수평 해상도는 0.1m입니다. 미끄러운 표면, 경사진 지형, 예측 불가능한 협곡 등 다양한 도전 과제를 포함한 총 9개의 환경이 사용되었습니다.</p>
<p>ADTG의 일반화 능력이 다양한 지형 조건에서도 유지되는지를 검증하기 위해, Jackal과 동일한 환경에서 Unitree Go1 4족 보행 로봇을 이용해 PGC 및 내장 MPC 컨트롤러와의 벤치마크 실험을 수행했습니다. ADTG와 PGC 정책은 모두 Parkour [66]의 “걷기” 정책을 기반으로 훈련되었습니다.</p>
<p>하이킹 실험 [5, 13]과 유사하게, 공정성을 위해 로봇은 MPC가 생성한 발자국 경로를 따라 총 1.2km에 달하는 루프를 연속 주행했으며, 경로 내 어려운 구간을 우회할 수 없는 경우 전복을 실패로 간주했습니다.</p>
<p>실험 결과, MPC는 총 6회 전복되었고, 이 중 3회는 고속 명령 수행 중, 나머지 3회는 자갈 및 모래 지형에서 발생했습니다. ADTG 정책은 고속 명령에 의한 2회의 실패가 있었으나 전반적으로 자연스럽고 안정적인 보행 자세를 유지했습니다. 반면, PGC 정책은 강한 수평 자세를 보였음에도 불구하고, 전 지형에서 발생한 갑작스러운 점프 동작으로 인해 총 11회의 전복이 발생했습니다.</p>
<p>이 같은 결과는 ADTG 정책이 다양한 환경에서 보다 안정적이고 일반화된 보행 행동을 성공적으로 학습했음을 보여줍니다. PGC 정책의 불안정성은 과도하게 도전적인, 비현실적인 지형 조건에서의 훈련으로 인해 유도되었을 가능성이 있습니다.</p>
<p>ADTG와 내장된 Go1의 MPC 보행 제어는 자연스러운 동작을 보였으며, 프로시저 생성 커리큘럼(PGC) 기반 정책에 비해 더 안정적인 자세를 유지했습니다. 반면, PGC 기반 정책은 전반적으로 양호하게 작동했지만, 때때로 갑작스러운 점프 동작으로 인해 로봇이 뒤집히는 문제가 발생했습니다. 이러한 문제는 PGC가 지나치게 도전적인, 비현실적인 지형에서 훈련되었기 때문일 수 있습니다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/2025-04-13-diffusion-map/6.png" class="img-fluid figure-img"></p>
<figcaption>6</figcaption>
</figure>
</div>
</section>
<section id="디퓨전-기반-지형-생성의-장점과-향후-전망" class="level2">
<h2 class="anchored" data-anchor-id="디퓨전-기반-지형-생성의-장점과-향후-전망">디퓨전 기반 지형 생성의 장점과 향후 전망</h2>
<p>ADTG를 통해 확인된 가장 큰 성과는, <strong>딥러닝 기반 생성모델(디퓨전)</strong>을 활용하여 <strong>강화학습 환경</strong>을 더 똑똑하게 만들 수 있다는 점입니다. 전통적인 절차적 생성이나 무작위 환경 샘플링과 달리, <strong>디퓨전 모델</strong>은 실제 지형 데이터를 학습하여 얻은 <strong>복잡한 분포</strong>에서 샘플을 뽑아내기 때문에 <strong>현실성과 다양성</strong> 측면에서 월등합니다. 예를 들어, 바위가 흩어진 경사면이나 물이 고인 진흙탕처럼 <strong>사람이 일일이 매개변수로 규정하기 어려운 지형</strong>도 디퓨전 모델은 데이터만 주어지면 생성해낼 수 있습니다. ADTG는 여기에 한 걸음 더 나아가 <strong>현재 정책에 유용한 방향으로 생성과정을 제어</strong>했기 때문에, 필요하지 않은 극단적으로 복잡한 지형을 억제하고 <strong>학습 효율을 극대화</strong>할 수 있었습니다 ted)) 향후 <strong>강화학습과 생성 AI의 접목</strong>이 얼마나 큰 잠재력을 갖는지 보여주는 예시라고 할 수 있습니다.</p>
<p>앞으로 이 분야에는 몇 가지 흥미로운 확장 가능성이 있습니다. 첫째, 본 논문에서는 <strong>지형의 높이맵(heightmap)</strong>에 대해서만 디퓨전 모델을 사용했지만, 이를 넘어 <strong>3차원 구조물</strong>이나 <strong>도시 환경</strong> 생성에도 비슷한 기법을 적용할 수 있을 것입니다. 예를 들어, 자율주행 자동차의 학습을 위해 도로 환경을 디퓨전 모델로 생성하고 난이도를 조절하는 식입니다. 둘째, 디퓨전 모델의 <strong>조건부 제어</strong> 능력을 활용하면 특정한 시나리오(예: “돌이 많은 지형” 혹은 “물이 있는 지형”)를 생성하도록 유도하는 것도 가능할 것입니다. 이는 단순히 난이도뿐 아니라 <strong>환경의 종류나 속성</strong>까지 커리큘럼에 넣을 수 있게 해줄 것입니다.</p>
<p>요약하면, <strong>Adaptive Diffusion Terrain Generator (ADTG)</strong>는 강화학습 에이전트를 위한 환경을 <strong>디퓨전 생성모델로 자동 생성</strong>하고, 이를 <strong>정책의 학습 상태에 맞춰 조절</strong>함으로써, 일종의 <strong>자동 커리큘럼</strong>을 구현한 기법입니다. 기존의 제한적인 환경 생성 방식의 한계를 극복하고, 학습된 정책이 <strong>더 넓은 분포의 지형에 견고하게 일반화</strong>할 수 있도록 돕는 점이 인상적입니다. ADTG는 강화학습 연구자들에게 <strong>환경 설계</strong>에 대한 부담을 줄이는 동시에, <strong>학습 효율과 성능</strong>을 모두 높일 수 있는 새로운 방향을 제시합니다.</p>
<hr>
</section>
</section>
<section id="reference" class="level1">
<h1>Reference</h1>
<ul>
<li><a href="https://medium.com/@gitau_am/a-friendly-introduction-to-denoising-diffusion-probabilistic-models-cc76b8abef25#:~:text=What%20are%20DDPMs%3F">A friendly Introduction to Denoising Diffusion Probabilistic Models | by Antony M. Gitau | Medium</a></li>
</ul>
</section>
<section id="todo" class="level1">
<h1>TODO</h1>
<ul>
<li>DDPM Initial Noise Optimization</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>